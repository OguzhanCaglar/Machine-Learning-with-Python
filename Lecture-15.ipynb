{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Lecture-15\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yapay Sinir Ağlarıyla Lojistik Olmayan Regresyon Örneği\n",
    "\n",
    "Otomobillerin mil başına yaktıkları yakıtı tahmin edelim.\n",
    "\n",
    "https://archive.ics.uci.edu/dataset/9/auto+mpg\n",
    "https://www.kaggle.com/datasets/uciml/autompg-dataset\n",
    "\n",
    "mpg,cylinders,displacement,horsepower,weight,acceleration,model year,origin,car name\n",
    "\n",
    "mpg --> aracın mil başına yaktığı yakıtın galon miktarı (1 galon 3.78 litredir)\n",
    "cylinders --> Aracın silindir sayısı\n",
    "displacement --> Aracın motor hacmi\n",
    "horsepower --> aracın beygir gücü\n",
    "weight --> aracın ağırlığı\n",
    "acceleration --> aracın 100 km/h çıkma süresi (ivmelenmesi)\n",
    "model year --> model yılı\n",
    "origin --> Kategorik bir veri 1:USA, 2: Europe, 3: Japan\n",
    "car name --> arabanın modeli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0  1      2      3       4     5   6  7\n",
      "0    18.0  8  307.0  130.0  3504.0  12.0  70  1\n",
      "1    15.0  8  350.0  165.0  3693.0  11.5  70  1\n",
      "2    18.0  8  318.0  150.0  3436.0  11.0  70  1\n",
      "3    16.0  8  304.0  150.0  3433.0  12.0  70  1\n",
      "4    17.0  8  302.0  140.0  3449.0  10.5  70  1\n",
      "..    ... ..    ...    ...     ...   ...  .. ..\n",
      "393  27.0  4  140.0  86.00  2790.0  15.6  82  1\n",
      "394  44.0  4   97.0  52.00  2130.0  24.6  82  2\n",
      "395  32.0  4  135.0  84.00  2295.0  11.6  82  1\n",
      "396  28.0  4  120.0  79.00  2625.0  18.6  82  1\n",
      "397  31.0  4  119.0  82.00  2720.0  19.4  82  1\n",
      "\n",
      "[398 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"auto-mpg.data\", header=None, sep=r'\\s+', usecols=range(8))\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "398"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.iloc[:, 3] == '?').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = df[df.iloc[:, 3] != '?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>27.0</td>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>86.00</td>\n",
       "      <td>2790.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>44.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>52.00</td>\n",
       "      <td>2130.0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>32.0</td>\n",
       "      <td>4</td>\n",
       "      <td>135.0</td>\n",
       "      <td>84.00</td>\n",
       "      <td>2295.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>28.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>79.00</td>\n",
       "      <td>2625.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>31.0</td>\n",
       "      <td>4</td>\n",
       "      <td>119.0</td>\n",
       "      <td>82.00</td>\n",
       "      <td>2720.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>392 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0  1      2      3       4     5   6  7\n",
       "0    18.0  8  307.0  130.0  3504.0  12.0  70  1\n",
       "1    15.0  8  350.0  165.0  3693.0  11.5  70  1\n",
       "2    18.0  8  318.0  150.0  3436.0  11.0  70  1\n",
       "3    16.0  8  304.0  150.0  3433.0  12.0  70  1\n",
       "4    17.0  8  302.0  140.0  3449.0  10.5  70  1\n",
       "..    ... ..    ...    ...     ...   ...  .. ..\n",
       "393  27.0  4  140.0  86.00  2790.0  15.6  82  1\n",
       "394  44.0  4   97.0  52.00  2130.0  24.6  82  2\n",
       "395  32.0  4  135.0  84.00  2295.0  11.6  82  1\n",
       "396  28.0  4  120.0  79.00  2625.0  18.6  82  1\n",
       "397  31.0  4  119.0  82.00  2720.0  19.4  82  1\n",
       "\n",
       "[392 rows x 8 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dataset_df.iloc[:, 3] == '?').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "dataset = pd.get_dummies(dataset_df, columns=[7]).to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 18.,   8., 307., ...,   1.,   0.,   0.],\n",
       "       [ 15.,   8., 350., ...,   1.,   0.,   0.],\n",
       "       [ 18.,   8., 318., ...,   1.,   0.,   0.],\n",
       "       ...,\n",
       "       [ 32.,   4., 135., ...,   1.,   0.,   0.],\n",
       "       [ 28.,   4., 120., ...,   1.,   0.,   0.],\n",
       "       [ 31.,   4., 119., ...,   1.,   0.,   0.]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_x = dataset[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  8., 307., 130., ...,   1.,   0.,   0.],\n",
       "       [  8., 350., 165., ...,   1.,   0.,   0.],\n",
       "       [  8., 318., 150., ...,   1.,   0.,   0.],\n",
       "       ...,\n",
       "       [  4., 135.,  84., ...,   1.,   0.,   0.],\n",
       "       [  4., 120.,  79., ...,   1.,   0.,   0.],\n",
       "       [  4., 119.,  82., ...,   1.,   0.,   0.]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_y = dataset[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18. , 15. , 18. , 16. , 17. , 15. , 14. , 14. , 14. , 15. , 15. ,\n",
       "       14. , 15. , 14. , 24. , 22. , 18. , 21. , 27. , 26. , 25. , 24. ,\n",
       "       25. , 26. , 21. , 10. , 10. , 11. ,  9. , 27. , 28. , 25. , 19. ,\n",
       "       16. , 17. , 19. , 18. , 14. , 14. , 14. , 14. , 12. , 13. , 13. ,\n",
       "       18. , 22. , 19. , 18. , 23. , 28. , 30. , 30. , 31. , 35. , 27. ,\n",
       "       26. , 24. , 25. , 23. , 20. , 21. , 13. , 14. , 15. , 14. , 17. ,\n",
       "       11. , 13. , 12. , 13. , 19. , 15. , 13. , 13. , 14. , 18. , 22. ,\n",
       "       21. , 26. , 22. , 28. , 23. , 28. , 27. , 13. , 14. , 13. , 14. ,\n",
       "       15. , 12. , 13. , 13. , 14. , 13. , 12. , 13. , 18. , 16. , 18. ,\n",
       "       18. , 23. , 26. , 11. , 12. , 13. , 12. , 18. , 20. , 21. , 22. ,\n",
       "       18. , 19. , 21. , 26. , 15. , 16. , 29. , 24. , 20. , 19. , 15. ,\n",
       "       24. , 20. , 11. , 20. , 19. , 15. , 31. , 26. , 32. , 25. , 16. ,\n",
       "       16. , 18. , 16. , 13. , 14. , 14. , 14. , 29. , 26. , 26. , 31. ,\n",
       "       32. , 28. , 24. , 26. , 24. , 26. , 31. , 19. , 18. , 15. , 15. ,\n",
       "       16. , 15. , 16. , 14. , 17. , 16. , 15. , 18. , 21. , 20. , 13. ,\n",
       "       29. , 23. , 20. , 23. , 24. , 25. , 24. , 18. , 29. , 19. , 23. ,\n",
       "       23. , 22. , 25. , 33. , 28. , 25. , 25. , 26. , 27. , 17.5, 16. ,\n",
       "       15.5, 14.5, 22. , 22. , 24. , 22.5, 29. , 24.5, 29. , 33. , 20. ,\n",
       "       18. , 18.5, 17.5, 29.5, 32. , 28. , 26.5, 20. , 13. , 19. , 19. ,\n",
       "       16.5, 16.5, 13. , 13. , 13. , 31.5, 30. , 36. , 25.5, 33.5, 17.5,\n",
       "       17. , 15.5, 15. , 17.5, 20.5, 19. , 18.5, 16. , 15.5, 15.5, 16. ,\n",
       "       29. , 24.5, 26. , 25.5, 30.5, 33.5, 30. , 30.5, 22. , 21.5, 21.5,\n",
       "       43.1, 36.1, 32.8, 39.4, 36.1, 19.9, 19.4, 20.2, 19.2, 20.5, 20.2,\n",
       "       25.1, 20.5, 19.4, 20.6, 20.8, 18.6, 18.1, 19.2, 17.7, 18.1, 17.5,\n",
       "       30. , 27.5, 27.2, 30.9, 21.1, 23.2, 23.8, 23.9, 20.3, 17. , 21.6,\n",
       "       16.2, 31.5, 29.5, 21.5, 19.8, 22.3, 20.2, 20.6, 17. , 17.6, 16.5,\n",
       "       18.2, 16.9, 15.5, 19.2, 18.5, 31.9, 34.1, 35.7, 27.4, 25.4, 23. ,\n",
       "       27.2, 23.9, 34.2, 34.5, 31.8, 37.3, 28.4, 28.8, 26.8, 33.5, 41.5,\n",
       "       38.1, 32.1, 37.2, 28. , 26.4, 24.3, 19.1, 34.3, 29.8, 31.3, 37. ,\n",
       "       32.2, 46.6, 27.9, 40.8, 44.3, 43.4, 36.4, 30. , 44.6, 33.8, 29.8,\n",
       "       32.7, 23.7, 35. , 32.4, 27.2, 26.6, 25.8, 23.5, 30. , 39.1, 39. ,\n",
       "       35.1, 32.3, 37. , 37.7, 34.1, 34.7, 34.4, 29.9, 33. , 33.7, 32.4,\n",
       "       32.9, 31.6, 28.1, 30.7, 25.4, 24.2, 22.4, 26.6, 20.2, 17.6, 28. ,\n",
       "       27. , 34. , 31. , 29. , 27. , 24. , 36. , 37. , 31. , 38. , 36. ,\n",
       "       36. , 36. , 34. , 38. , 32. , 38. , 25. , 38. , 26. , 22. , 32. ,\n",
       "       36. , 27. , 27. , 44. , 32. , 28. , 31. ], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = train_test_split(dataset_x, dataset_y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# veri kümemizde sütunların mertebeleri arasında ciddi farklar vardır. Bunun için \"özellik ölçeklendirmesi (feature scaling)\"\n",
    "# yapmamız gerekir. Min-Max Ölçeklemesini kullanalım.\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "mms = MinMaxScaler()\n",
    "mms.fit(dataset_x)\n",
    "scaled_training_dataset_x = mms.transform(training_dataset_x)\n",
    "scaled_test_dataset_x = mms.transform(test_dataset_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19999999, 0.07493539, 0.11413044, ..., 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [1.        , 0.73126614, 0.58152175, ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.6       , 0.49095607, 0.34782612, ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.19999999, 0.22739018, 0.25      , ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.19999999, 0.13953488, 0.18478262, ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.19999999, 0.13436691, 0.22826087, ..., 0.        , 1.        ,\n",
       "        0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_training_dataset_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.73126614, 0.5543478 , 0.8630564 , 0.32738096,\n",
       "        0.4166665 , 1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.8578811 , 0.56521744, 0.9594556 , 0.35714287,\n",
       "        0.25      , 1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.49612403, 0.34782612, 0.49673945, 0.4464286 ,\n",
       "        0.6666665 , 1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.8578811 , 1.        , 0.7555996 , 0.08928573,\n",
       "        0.25      , 1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.64599484, 0.56521744, 0.81797564, 0.38690478,\n",
       "        0.4166665 , 1.        , 0.        , 0.        ],\n",
       "       [0.19999999, 0.07493539, 0.22826087, 0.1465835 , 0.38690478,\n",
       "        0.08333349, 0.        , 0.        , 1.        ],\n",
       "       [0.19999999, 0.04651162, 0.10326087, 0.11511201, 0.5       ,\n",
       "        0.8333335 , 0.        , 0.        , 1.        ],\n",
       "       [0.19999999, 0.09560724, 0.1521739 , 0.10405445, 0.43452382,\n",
       "        1.        , 0.        , 1.        , 0.        ],\n",
       "       [0.19999999, 0.18863048, 0.13586956, 0.44712222, 1.        ,\n",
       "        0.75      , 0.        , 1.        , 0.        ],\n",
       "       [0.19999999, 0.        , 0.01630434, 0.07201588, 0.6845239 ,\n",
       "        0.25      , 0.        , 1.        , 0.        ],\n",
       "       [0.19999999, 0.07493539, 0.07608697, 0.0626595 , 0.65476197,\n",
       "        0.08333349, 0.        , 1.        , 0.        ],\n",
       "       [0.6       , 0.25839794, 0.3804348 , 0.36489934, 0.27380955,\n",
       "        0.9166665 , 0.        , 0.        , 1.        ],\n",
       "       [1.        , 0.72868216, 0.5380435 , 0.6733768 , 0.29761904,\n",
       "        0.25      , 1.        , 0.        , 0.        ],\n",
       "       [0.6       , 0.40568477, 0.29347825, 0.57782817, 0.5773811 ,\n",
       "        0.5       , 1.        , 0.        , 0.        ],\n",
       "       [0.19999999, 0.10335918, 0.26086956, 0.21718174, 0.5059524 ,\n",
       "        0.25      , 0.        , 0.        , 1.        ],\n",
       "       [1.        , 0.75452197, 0.56521744, 0.6597675 , 0.29761904,\n",
       "        0.75      , 1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.72868216, 0.7282609 , 0.8182591 , 0.26785713,\n",
       "        0.25      , 1.        , 0.        , 0.        ],\n",
       "       [0.19999999, 0.07751937, 0.17934784, 0.18202442, 0.5773811 ,\n",
       "        0.5       , 1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.6098191 , 0.56521744, 0.5160193 , 0.23809522,\n",
       "        0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.19999999, 0.02842377, 0.11413044, 0.09923446, 0.4464286 ,\n",
       "        0.3333335 , 0.        , 1.        , 0.        ],\n",
       "       [1.        , 0.72868216, 0.7282609 , 0.581514  , 0.17857146,\n",
       "        0.25      , 1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.60465115, 0.451087  , 0.59880924, 0.3214286 ,\n",
       "        0.75      , 1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.49612403, 0.23913044, 0.51233345, 0.84523815,\n",
       "        0.75      , 1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.72868216, 0.6467391 , 0.7360363 , 0.23809522,\n",
       "        0.08333349, 1.        , 0.        , 0.        ],\n",
       "       [0.19999999, 0.07493539, 0.13586956, 0.06010777, 0.25      ,\n",
       "        0.5       , 0.        , 1.        , 0.        ],\n",
       "       [0.19999999, 0.11886306, 0.24456522, 0.27473772, 0.35714287,\n",
       "        0.25      , 0.        , 1.        , 0.        ],\n",
       "       [1.        , 0.64599484, 0.51086956, 0.69946134, 0.33928573,\n",
       "        0.6666665 , 1.        , 0.        , 0.        ],\n",
       "       [0.6       , 0.47028422, 0.17391306, 0.55599666, 0.7738096 ,\n",
       "        0.5       , 1.        , 0.        , 0.        ],\n",
       "       [0.6       , 0.34108526, 0.21195653, 0.3904168 , 0.607143  ,\n",
       "        0.75      , 1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.73126614, 0.576087  , 0.7377374 , 0.28571433,\n",
       "        0.5       , 1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.60465115, 0.51086956, 0.71675646, 0.35714287,\n",
       "        0.3333335 , 1.        , 0.        , 0.        ],\n",
       "       [0.6       , 0.40568477, 0.29347825, 0.57187414, 0.5773811 ,\n",
       "        0.5833335 , 1.        , 0.        , 0.        ],\n",
       "       [0.19999999, 0.18604653, 0.25      , 0.35497588, 0.5       ,\n",
       "        1.        , 1.        , 0.        , 0.        ],\n",
       "       [0.19999999, 0.05684754, 0.15760872, 0.14516586, 0.38690478,\n",
       "        0.3333335 , 1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.96124035, 0.91847825, 0.7652396 , 0.02976191,\n",
       "        0.        , 1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.64599484, 0.56521744, 0.51686984, 0.17857146,\n",
       "        0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.19999999, 0.11627908, 0.26630437, 0.17436916, 0.35714287,\n",
       "        0.08333349, 0.        , 0.        , 1.        ],\n",
       "       [0.6       , 0.47028422, 0.29347825, 0.4720726 , 0.59523815,\n",
       "        0.25      , 1.        , 0.        , 0.        ],\n",
       "       [0.6       , 0.47028422, 0.14130434, 0.51573575, 0.7738096 ,\n",
       "        0.4166665 , 1.        , 0.        , 0.        ],\n",
       "       [0.19999999, 0.04392764, 0.13043478, 0.12957186, 0.6309524 ,\n",
       "        0.6666665 , 0.        , 0.        , 1.        ],\n",
       "       [1.        , 0.72868216, 0.5923913 , 0.8191097 , 0.32738096,\n",
       "        0.16666651, 1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.61757106, 0.45652175, 0.5361497 , 0.23809522,\n",
       "        0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.19999999, 0.1136951 , 0.22826087, 0.22171819, 0.59523815,\n",
       "        1.        , 1.        , 0.        , 0.        ],\n",
       "       [0.19999999, 0.17312662, 0.20652175, 0.21463001, 0.29761904,\n",
       "        1.        , 1.        , 0.        , 0.        ],\n",
       "       [0.19999999, 0.13436691, 0.1521739 , 0.2897647 , 0.6130952 ,\n",
       "        0.9166665 , 0.        , 0.        , 1.        ],\n",
       "       [0.6       , 0.4211886 , 0.34782612, 0.5109158 , 0.46428573,\n",
       "        0.9166665 , 1.        , 0.        , 0.        ],\n",
       "       [0.19999999, 0.1007752 , 0.23913044, 0.23164165, 0.38690478,\n",
       "        0.        , 0.        , 1.        , 0.        ],\n",
       "       [1.        , 0.64599484, 0.5380435 , 0.71647286, 0.33928573,\n",
       "        0.5833335 , 1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.64599484, 0.56521744, 0.74397504, 0.38690478,\n",
       "        0.25      , 1.        , 0.        , 0.        ],\n",
       "       [0.19999999, 0.07751937, 0.07608697, 0.15622342, 0.8392858 ,\n",
       "        0.5       , 1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.72868216, 0.6467391 , 0.58973634, 0.20833337,\n",
       "        0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.6       , 0.40568477, 0.3206522 , 0.42755884, 0.5059524 ,\n",
       "        0.25      , 1.        , 0.        , 0.        ],\n",
       "       [0.19999999, 0.07493539, 0.22826087, 0.18882906, 0.65476197,\n",
       "        0.25      , 0.        , 0.        , 1.        ],\n",
       "       [0.6       , 0.40568477, 0.3206522 , 0.51772046, 0.4464286 ,\n",
       "        0.08333349, 1.        , 0.        , 0.        ],\n",
       "       [1.        , 1.0000001 , 0.9728261 , 0.9464134 , 0.17857146,\n",
       "        0.25      , 1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.8578811 , 0.56521744, 0.80833566, 0.23809522,\n",
       "        0.25      , 1.        , 0.        , 0.        ],\n",
       "       [0.19999999, 0.05943152, 0.11956522, 0.10121918, 0.5714286 ,\n",
       "        1.        , 0.        , 0.        , 1.        ],\n",
       "       [0.19999999, 0.07751937, 0.18478262, 0.08562517, 0.38095236,\n",
       "        0.75      , 1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.8578811 , 0.701087  , 0.80833566, 0.20833337,\n",
       "        0.08333349, 1.        , 0.        , 0.        ],\n",
       "       [0.19999999, 0.17312662, 0.20652175, 0.19336545, 0.21428573,\n",
       "        1.        , 1.        , 0.        , 0.        ],\n",
       "       [0.19999999, 0.17054264, 0.23913044, 0.31131274, 0.4464286 ,\n",
       "        0.8333335 , 0.        , 0.        , 1.        ],\n",
       "       [0.6       , 0.42377257, 0.29347825, 0.36518288, 0.4761905 ,\n",
       "        0.3333335 , 1.        , 0.        , 0.        ],\n",
       "       [0.19999999, 0.04392764, 0.10326087, 0.14091295, 0.6666668 ,\n",
       "        0.8333335 , 0.        , 0.        , 1.        ],\n",
       "       [1.        , 0.72868216, 0.5380435 , 0.69237316, 0.23809522,\n",
       "        0.5       , 1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.64599484, 0.56521744, 0.60731494, 0.35714287,\n",
       "        0.5       , 1.        , 0.        , 0.        ],\n",
       "       [0.6       , 0.47028422, 0.22826087, 0.4326623 , 0.38690478,\n",
       "        0.08333349, 1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.6098191 , 0.56521744, 0.5837822 , 0.20833337,\n",
       "        0.16666651, 1.        , 0.        , 0.        ],\n",
       "       [0.19999999, 0.07622738, 0.18478262, 0.1454494 , 0.5357143 ,\n",
       "        0.16666651, 1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.64599484, 0.56521744, 0.70399773, 0.29761904,\n",
       "        0.08333349, 1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.64599484, 0.56521744, 0.6135526 , 0.26785713,\n",
       "        0.25      , 1.        , 0.        , 0.        ],\n",
       "       [0.19999999, 0.07493539, 0.11413044, 0.15083641, 0.59523815,\n",
       "        0.8333335 , 0.        , 0.        , 1.        ],\n",
       "       [0.6       , 0.47028422, 0.2826087 , 0.54210377, 0.65476197,\n",
       "        0.5833335 , 1.        , 0.        , 0.        ],\n",
       "       [0.19999999, 0.1136951 , 0.22826087, 0.29118234, 0.6309524 ,\n",
       "        1.        , 1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.501292  , 0.34782612, 0.45591152, 0.32738096,\n",
       "        0.4166665 , 1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.73126614, 0.6086957 , 0.77969944, 0.29761904,\n",
       "        0.25      , 1.        , 0.        , 0.        ],\n",
       "       [0.19999999, 0.12403099, 0.23913044, 0.14459884, 0.35714287,\n",
       "        0.08333349, 0.        , 1.        , 0.        ],\n",
       "       [0.19999999, 0.12403099, 0.1902174 , 0.17210096, 0.52976197,\n",
       "        0.5       , 0.        , 1.        , 0.        ],\n",
       "       [1.        , 0.75452197, 0.67391306, 0.86220586, 0.29761904,\n",
       "        0.25      , 1.        , 0.        , 0.        ],\n",
       "       [0.19999999, 0.07751937, 0.11956522, 0.14800113, 0.51190484,\n",
       "        0.6666665 , 0.        , 0.        , 1.        ]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_test_dataset_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelimizde 2 saklı katman olabilir. saklı katmanlar için aktivasyon fonksiyonlarını 'relu', çıktı katmanı için de \"linear\" alabilirz.\n",
    "# Optimizer algoritması olarak \"sgd\", \"adam\", \"rmsprop\" herhangi birini seçebiliriz. rmsprop seçelim. Lojistik olmayan regresyon modellerinde\n",
    "# loss fonksiyonunun genellikle \"mse\" ve metrik değerin de \"mae\" olarak kullanılır.\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential(name='AutoMPG')\n",
    "model.add(Dense(64, input_dim=training_dataset_x.shape[1], activation='relu', name='Hidden-1'))\n",
    "model.add(Dense(64, activation='relu', name='Hidden-2'))\n",
    "model.add(Dense(1, activation='linear', name='Output'))\n",
    "\n",
    "model.compile('rmsprop', loss='mse', metrics=['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(scaled_test_dataset_x, training_dataset_y, validation_split=0.2, batch_size=32, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "figure = plt.gcf()\n",
    "figure.set_size_inches((15, 5))\n",
    "plt.title('Loss - Epoch Graphics')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(hist.epoch, hist.history['loss'])\n",
    "plt.plot(hist.epoch, hist.history['val_loss'])\n",
    "plt.legend(['Loss', 'Validation Loss'])\n",
    "plt.show()\n",
    "\n",
    "figure = plt.gcf()\n",
    "figure.set_size_inches((15, 5))\n",
    "plt.title('Binary Accuracy - Epoch Graphics')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Binary Accuracy')\n",
    "plt.plot(hist.epoch, hist.history['binary_accuracy'])\n",
    "plt.plot(hist.epoch, hist.history['val_binary_accuracy'])\n",
    "plt.legend(['Binary Accuracy', 'Validation Binary Accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss: ...\n",
    "# mae: ... -> bu değer gerçek değer ile tahmin edilen değer arasındaki ortalama sapmayı belirtmektedir. Yani \n",
    "# biz bir tahmin yaptığımızda tahmin ettiğiiz değer gerçek değerin ortalama mae değeri kadar uzağında olacaktır.\n",
    "eval_result = model.evaluate(scaled_test_dataset_x, test_dataset_y)\n",
    "for i in range(len(eval_result)):\n",
    "    print(f'{model.metrics_names[i]}: {eval_result[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tahmin işlemini yapalım.\n",
    "predict_data = np.array([4., 113., 95, 2228., 14., 71., 0, 0, 1], dtype='float32')\n",
    "predict_data = mms.transform(predict_data)\n",
    "predict_result = model.predict(predict_data)\n",
    "print(predict_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# birden fazla data'yı tahmin etme\n",
    "predict_df = pd.read_csv('predict_data.csv', header=None)\n",
    "predict_data = pd.get_dummies(predict_df, columns=[6]).to_numpy()\n",
    "\n",
    "scaled_predict_data = mms.transform(predict_data)\n",
    "predict_result = model.predict(scaled_predict_data)\n",
    "\n",
    "for val in predict_result[:, 0]:\n",
    "    print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('auto-mpg.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeli yükledikten sonra predict işlemi yapmadan önce bizim predict edilecek verileri feature scaling yapmamız gerekir. Halbuki bunun için oluşturmuş olduğumuz MinMaxScaler nesnesini biz bir yerde kaydetmedik. Sınıf nesnelerini içlerindeki verilerle diske bir dosya içerisinde saklayabiliriz. Bu işleme \"nesnelerin seri hale getirilmesi\" (object serialization) denilmektedir. pickle\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('autompg.pickle', 'wb') as f:\n",
    "    pickle.dump(mms, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import pickle\n",
    "\n",
    "model = load_model('auto-mpg.h5')\n",
    "\n",
    "with open('autompg.pickle', 'wb') as f:\n",
    "    mms = pickle.load(f)\n",
    "\n",
    "predict_data = np.array([[8,307,130,3504,12,70,0, 0, 1]], dtype='float32')\n",
    "predict_data = mms.transform(predict_data)\n",
    "\n",
    "predict_result = model.predict(predict_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
